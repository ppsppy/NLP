{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "语言模型、HMM模型、CRF模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隐马尔可夫模型是将分词作为字在字符串中的序列标注任务来完成的，基本思路是：每个字在构成一个特定的词语时都占据一个确定的构词位置（B开始，M中间，E结尾，S独立词）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练数据是已经分词好了的文本，对文本进行标记，每一个字都有（BMES）四种可能，需要计算在这四种可能下，每一个字的概率，和在这四种可能下，下一个字的四种状态的概率，然后对目标文本进行预测，预测方法是veterbi算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    def __init__(self):\n",
    "        import os\n",
    "\n",
    "        # 主要是用于存取算法中间结果，不用每次都训练模型\n",
    "        self.model_file = './data/hmm_model.pkl'\n",
    "\n",
    "        # 状态值集合\n",
    "        self.state_list = ['B', 'M', 'E', 'S']\n",
    "        # 参数加载,用于判断是否需要重新加载model_file\n",
    "        self.load_para = False\n",
    "\n",
    "    # 用于加载已计算的中间结果，当需要重新训练时，需初始化清空结果\n",
    "    def try_load_model(self, trained):\n",
    "        if trained:\n",
    "            import pickle\n",
    "            with open(self.model_file, 'rb') as f:\n",
    "                self.A_dic = pickle.load(f)\n",
    "                self.B_dic = pickle.load(f)\n",
    "                self.Pi_dic = pickle.load(f)\n",
    "                self.load_para = True\n",
    "\n",
    "        else:\n",
    "            # 状态转移概率（状态->状态的条件概率）\n",
    "            self.A_dic = {}\n",
    "            # 发射概率（状态->词语的条件概率）\n",
    "            self.B_dic = {}\n",
    "            # 状态的初始概率\n",
    "            self.Pi_dic = {}\n",
    "            self.load_para = False\n",
    "\n",
    "    # 计算转移概率、发射概率以及初始概率\n",
    "    def train(self, path):\n",
    "\n",
    "        # 重置几个概率矩阵\n",
    "        self.try_load_model(False)\n",
    "\n",
    "        # 统计状态出现次数，求p(o)\n",
    "        Count_dic = {}\n",
    "\n",
    "        # 初始化参数\n",
    "        def init_parameters():\n",
    "            for state in self.state_list:\n",
    "                self.A_dic[state] = {s: 0.0 for s in self.state_list}\n",
    "                self.Pi_dic[state] = 0.0\n",
    "                self.B_dic[state] = {}\n",
    "\n",
    "                Count_dic[state] = 0\n",
    "\n",
    "        def makeLabel(text):\n",
    "            out_text = []\n",
    "            if len(text) == 1:\n",
    "                out_text.append('S')\n",
    "            else:\n",
    "                out_text += ['B'] + ['M'] * (len(text) - 2) + ['E']\n",
    "\n",
    "            return out_text\n",
    "\n",
    "        init_parameters()\n",
    "        line_num = -1\n",
    "        # 观察者集合，主要是字以及标点等\n",
    "        words = set()\n",
    "        with open(path, encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                line_num += 1\n",
    "\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                word_list = [i for i in line if i != ' ']\n",
    "                words |= set(word_list)  # 更新字的集合\n",
    "\n",
    "                linelist = line.split()\n",
    "\n",
    "                line_state = []\n",
    "                for w in linelist:\n",
    "                    line_state.extend(makeLabel(w))\n",
    "                \n",
    "                assert len(word_list) == len(line_state)\n",
    "\n",
    "                for k, v in enumerate(line_state):\n",
    "                    Count_dic[v] += 1\n",
    "                    if k == 0:\n",
    "                        self.Pi_dic[v] += 1  # 每个句子的第一个字的状态，用于计算初始状态概率\n",
    "                    else:\n",
    "                        self.A_dic[line_state[k - 1]][v] += 1  # 计算转移概率\n",
    "                        self.B_dic[line_state[k]][word_list[k]] = \\\n",
    "                            self.B_dic[line_state[k]].get(word_list[k], 0) + 1.0  # 计算发射概率\n",
    "        \n",
    "        self.Pi_dic = {k: v * 1.0 / line_num for k, v in self.Pi_dic.items()}\n",
    "        self.A_dic = {k: {k1: v1 / Count_dic[k] for k1, v1 in v.items()}\n",
    "                      for k, v in self.A_dic.items()}\n",
    "        #加1平滑\n",
    "        self.B_dic = {k: {k1: (v1 + 1) / Count_dic[k] for k1, v1 in v.items()}\n",
    "                      for k, v in self.B_dic.items()}\n",
    "        #序列化\n",
    "        import pickle\n",
    "        with open(self.model_file, 'wb') as f:\n",
    "            pickle.dump(self.A_dic, f)\n",
    "            pickle.dump(self.B_dic, f)\n",
    "            pickle.dump(self.Pi_dic, f)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def viterbi(self, text, states, start_p, trans_p, emit_p):\n",
    "        V = [{}]\n",
    "        path = {}\n",
    "        for y in states:\n",
    "            V[0][y] = start_p[y] * emit_p[y].get(text[0], 0)\n",
    "            path[y] = [y]\n",
    "        for t in range(1, len(text)):\n",
    "            V.append({})\n",
    "            newpath = {}\n",
    "            \n",
    "            #检验训练的发射概率矩阵中是否有该字\n",
    "            neverSeen = text[t] not in emit_p['S'].keys() and \\\n",
    "                text[t] not in emit_p['M'].keys() and \\\n",
    "                text[t] not in emit_p['E'].keys() and \\\n",
    "                text[t] not in emit_p['B'].keys()\n",
    "            for y in states:\n",
    "                emitP = emit_p[y].get(text[t], 0) if not neverSeen else 1.0 #设置未知字单独成词\n",
    "                (prob, state) = max(\n",
    "                    [(V[t - 1][y0] * trans_p[y0].get(y, 0) *\n",
    "                      emitP, y0)\n",
    "                     for y0 in states if V[t - 1][y0] > 0])\n",
    "                V[t][y] = prob\n",
    "                newpath[y] = path[state] + [y]\n",
    "            path = newpath\n",
    "            \n",
    "        if emit_p['M'].get(text[-1], 0)> emit_p['S'].get(text[-1], 0):\n",
    "            (prob, state) = max([(V[len(text) - 1][y], y) for y in ('E','M')])\n",
    "        else:\n",
    "            (prob, state) = max([(V[len(text) - 1][y], y) for y in states])\n",
    "        \n",
    "        return (prob, path[state])\n",
    "\n",
    "    def cut(self, text):\n",
    "        import os\n",
    "        if not self.load_para:\n",
    "            self.try_load_model(os.path.exists(self.model_file))\n",
    "        prob, pos_list = self.viterbi(text, self.state_list, self.Pi_dic, self.A_dic, self.B_dic)      \n",
    "        begin, next = 0, 0    \n",
    "        for i, char in enumerate(text):\n",
    "            pos = pos_list[i]\n",
    "            if pos == 'B':\n",
    "                begin = i\n",
    "            elif pos == 'E':\n",
    "                yield text[begin: i+1]\n",
    "                next = i+1\n",
    "            elif pos == 'S':\n",
    "                yield char\n",
    "                next = i+1\n",
    "        if next < len(text):\n",
    "            yield text[next:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hmm模型粗糙版"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "\n",
    "#读取文本\n",
    "with open('train_text.txt','r')as f:\n",
    "    raw_text=f.read()\n",
    "\n",
    "#消除'\\n'\n",
    "raw_text=re.sub(r'\\n',' ',raw_text)\n",
    "\n",
    "#建立三个字典，分别存储计算发射概率、转移概率、初始概率\n",
    "#初始概率是一句话的开头是S还是B的概率\n",
    "\n",
    "dic_A={}\n",
    "dic_B={}\n",
    "dic_Pi={'B':0,'S':0}\n",
    "\n",
    "#初始化字典A\n",
    "word_list=[]\n",
    "for word in raw_text:\n",
    "    word_list.append(word)\n",
    "word_list=set(word_list)\n",
    "\n",
    "for word in word_list:\n",
    "    dic_A[word]=[0]*4\n",
    "\n",
    "#初始化字典B\n",
    "for i in 'BMES':\n",
    "    dic_B[i]=[0]*4\n",
    "\n",
    "#完善字典Pi    \n",
    "sentences=raw_text.split('。')\n",
    "for sent in sentences:\n",
    "    if len(sent.split()[0])==0:\n",
    "        continue\n",
    "    if len(sent.split()[0])==1:\n",
    "        dic_Pi['S']+=1\n",
    "    else:\n",
    "        dic_Pi['B']+=1\n",
    "\n",
    "#完善字典A，并为字典B做准备        \n",
    "text_list=raw_text.split()\n",
    "Token=[]\n",
    "sum_of_state=[0]*4\n",
    "for i,phrase in enumerate(text_list):\n",
    "    if len(phrase)==0:\n",
    "        continue\n",
    "    if len(phrase)==1:\n",
    "        dic_A[phrase][3]+=1\n",
    "        Token.append('S')\n",
    "        sum_of_state[3]+=1\n",
    "    elif len(phrase)==2:\n",
    "        dic_A[phrase[0]][0]+=1\n",
    "        Token.append('B')\n",
    "        sum_of_state[0]+=1\n",
    "        dic_A[phrase[1]][2]+=1\n",
    "        Token.append('E')\n",
    "        sum_of_state[2]+=1\n",
    "    else:\n",
    "        dic_A[phrase[0]][0]+=1\n",
    "        Token.append('B')\n",
    "        sum_of_state[0]+=1\n",
    "        for word in phrase[1:-1]:\n",
    "            dic_A[word][1]+=1\n",
    "            Token.append('M')\n",
    "            sum_of_state[1]+=1\n",
    "        dic_A[phrase[-1]][2]+=1\n",
    "        Token.append('E')\n",
    "        sum_of_state[2]+=1\n",
    "\n",
    "#完善字典B\n",
    "pre_Token=Token[:-1]\n",
    "next_Token=Token[1:]\n",
    "for i,token in enumerate(pre_Token):\n",
    "    if next_Token[i]=='B':\n",
    "        dic_B[token][0]+=1\n",
    "    elif next_Token[i]=='M':\n",
    "        dic_B[token][1]+=1\n",
    "    elif next_Token[i]=='E':\n",
    "        dic_B[token][2]+=1\n",
    "    elif next_Token[i]=='S':\n",
    "        dic_B[token][3]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算转移概率分布、发射概率分布和初始概率分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已经有了计数，接下来计算转移概率分布、发射概率分布和初始概率分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dic_init、dic_launch、dic_change分别记录初始概率，发射概率(当前点是B/W/E/S的概率)和转移概率（上一个点是B/W/E/S时，下一个点是B/W/E/S的概率）\n",
    "import copy\n",
    "dic_init={}\n",
    "dic_init['B']=dic_Pi['B']/(dic_Pi['B']+dic_Pi['S'])\n",
    "dic_init['S']=1-dic_init['B']\n",
    "dic_init['M']=0\n",
    "dic_init['E']=0\n",
    "dic_launch=copy.deepcopy(dic_A)\n",
    "for key in dic_A.keys():\n",
    "    for i in range(4):\n",
    "        dic_launch[key][i]=dic_A[key][i]/sum_of_state[i]\n",
    "        \n",
    "dic_change=copy.deepcopy(dic_B)\n",
    "for i in 'BMES':\n",
    "    SUM=dic_B[i][0]+dic_B[i][1]+dic_B[i][2]+dic_B[i][3]\n",
    "    for j in range(4):\n",
    "        dic_change[i][j]=dic_B[i][j]/SUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### viterbi算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个点最优路径的前一个节点也是最优路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test='这是一个非常棒的方案！'\n",
    "\n",
    "P_now=dic_init.copy()#dict对象，键值BMES的值分别表示当前节点的最大概率\n",
    "\n",
    "output=[[] for i in range(4)]#记录最优路径\n",
    "\n",
    "#先计算前两个节点的最优概率\n",
    "#初始字符的概率是初始字的概率乘以初始概率\n",
    "\n",
    "word=test[0]\n",
    "for index,label in enumerate('BMES'):\n",
    "    P_now[label]=P_now[label]*dic_launch[word][index]\n",
    "#此时用于计算第一层的分布\n",
    "word=test[1]\n",
    "pre_P=copy.deepcopy(P_now)\n",
    "for index,label in enumerate('BMES'):\n",
    "    #计算上一节点概率分布和当前节点的概率分布的乘积，当前节点每个位置选择最优路径\n",
    "    operation= [pre_P['B']*dic_change['B'][index]*dic_launch[word][index],\\\n",
    "            pre_P['M']*dic_change['M'][index]*dic_launch[word][index],\\\n",
    "            pre_P['E']*dic_change['E'][index]*dic_launch[word][index],\\\n",
    "            pre_P['S']*dic_change['S'][index]*dic_launch[word][index]]\n",
    "    #到达label的最佳路径是从'BMES'[max(operation)]到label的路径\n",
    "    P_now[label]=max(operation)\n",
    "    #当前选择的最优节点的index是operation.index(max(operation))\n",
    "    #上次选择的节点，加上本次到达的节点就是当前节点的最优路径\n",
    "    output[index]='BMES'[operation.index(max(operation))]+label\n",
    "for word in test[2:]:\n",
    "    #用pre_output来记录上一节点中的最优路径\n",
    "    pre_P=copy.deepcopy(P_now)\n",
    "    pre_output=copy.deepcopy(output)\n",
    "    for index,label in enumerate('BMES'):\n",
    "        operation= [pre_P['B']*dic_change['B'][index]*dic_launch[word][index],\\\n",
    "                pre_P['M']*dic_change['M'][index]*dic_launch[word][index],\\\n",
    "                pre_P['E']*dic_change['E'][index]*dic_launch[word][index],\\\n",
    "                pre_P['S']*dic_change['S'][index]*dic_launch[word][index]]\n",
    "        P_now[label]=max(operation)\n",
    "        output[index]=pre_output[operation.index(max(operation))]+label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这/是/一个/非常/棒/的/方案/！\n"
     ]
    }
   ],
   "source": [
    "MAX=0\n",
    "for key in 'BMES':\n",
    "    if P_now[key]>MAX:\n",
    "        P_now[key]\n",
    "        index=key\n",
    "for i in output:\n",
    "    if i[-1]=='S':\n",
    "        LIST=i \n",
    "f=[]\n",
    "index=0\n",
    "for i,value in enumerate(LIST):\n",
    "    if value == 'S':\n",
    "        f.append(test[index:i+1])\n",
    "        index=i+1\n",
    "    if value == 'E':\n",
    "        f.append(test[index:i+1])\n",
    "        index=i+1\n",
    "seq='/'.join(f)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
